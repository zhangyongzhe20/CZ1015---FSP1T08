{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitbaseconda358eabea45a24d73875c3dc09bc71b6a",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Price Pridiction for Holiday Listings.csv\n",
    "## One copy of the code for Non-holiday Listings.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# For Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For Calculations\n",
    "from math import floor\n",
    "\n",
    "#For Modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression , Lasso, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import feature_selection\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# For Validation\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "\n",
    "# For Storing Models\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "\n",
    "# For Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_listings = pd.read_csv(\"..\\dataset_filter\\listings_holiday.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create Model Function: \n",
    "* train_set:test_set = 8:2\n",
    "* Display R^2 and MSE for comparing different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the train and test split\n",
    "np.random.seed(2018)\n",
    "train = np.random.choice([True, False], holiday_listings.shape[0], replace=True, p=[0.8, 0.2])\n",
    "listings_train = holiday_listings.iloc[train,:]\n",
    "listings_test = holiday_listings.iloc[~train,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(listings_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_listing(regr,train_cols,target_col):\n",
    "    \n",
    "    x_train = listings_train[train_cols].values\n",
    "    x_test = listings_test[train_cols].values\n",
    "    y_train = listings_train[target_col].values\n",
    "    y_test = listings_test[target_col].values\n",
    "    \n",
    "    print(\"Shape of Train and Test data\")\n",
    "    print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "    print(\" ------------------------------------------ \")\n",
    "    \n",
    "    #Min Max Scaling\n",
    "\n",
    "    #scaler = MinMaxScaler()\n",
    "    #x_train = scaler.fit_transform(x_train)\n",
    "    #x_test = scaler.transform(x_test)\n",
    "    \n",
    "    # Declare an instance of the Linear Regression model.\n",
    "    rg = regr()\n",
    "\n",
    "    # Fit the model on to the training data( Train the model ).\n",
    "    rg.fit(x_train, y_train)\n",
    "    \n",
    "    # Use the model to predict values\n",
    "    y_pred = rg.predict(x_train)\n",
    "\n",
    "    # Calculate the Mean Squared Error using the mean_squared_error function.\n",
    "    print(\"Training Data\")\n",
    "    print(\"R^2 value using score fn: %.3f\" % rg.score(x_train,y_train))\n",
    "    print(\"Mean Squared Error : %0.3f\" % mean_squared_error(y_train,y_pred))\n",
    "    print(\"Root Mean Squared Error : %0.3f\" % (mean_squared_error(y_train,y_pred))**0.5)\n",
    "    print(\" ------------------------------------------ \")\n",
    "    # Use the model to predict values\n",
    "    y_pred = rg.predict(x_test)\n",
    "\n",
    "    # Calculate the Mean Squared Error using the mean_squared_error function.\n",
    "    print(\"Test Data\")\n",
    "    print(\"R^2 value using score fn: %.3f\" % rg.score(x_test,y_test))\n",
    "    print(\"Mean Squared Error : %0.3f\" % mean_squared_error(y_test,y_pred))\n",
    "    print(\"Root Mean Squared Error : %0.3f\" % (mean_squared_error(y_test,y_pred)**0.5))\n",
    "    print(\" ------------------------------------------ \")\n",
    "    #print(lm.intercept_, lm.coef_)\n",
    "    \n",
    "    lin_reg_coef = pd.DataFrame(list(zip(train_cols,(rg.coef_))),columns=['Feature','Coefficient'])\n",
    "    print(lin_reg_coef.sort_values(by='Coefficient',ascending=False))\n",
    "    print(\" ------------------------------------------ \")\n",
    "    \n",
    "    # Plot of model's residuals:\n",
    "    fig = plt.figure(figsize=(10,3))\n",
    "\n",
    "    sns.regplot(y_test,y_pred)\n",
    "    plt.title(\"Residuals for the model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Linear Regresson + Basic Features\n",
    "## Basic Features are analyzed in the EDA, which have a high corelation with Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = [\n",
    "    ## Need to wait for EDA part\n",
    "\n",
    "]\n",
    "\n",
    "target_col = 'price_holiday'\n",
    "model_listing(LinearRegression,train_cols,target_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: Linear Regresson + Basic Features + Amenities Features,  Linear regresson can fit in Boolean???\n",
    "## Amenities are extracted by using One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = [\n",
    "   \n",
    "    \n",
    "]\n",
    "\n",
    "target_col = 'price_holiday'\n",
    "\n",
    "model_listing(LinearRegression,train_cols,target_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3\" Linear Regresson + Basic Features + Amenities Features + Seattle Score Features\n",
    "## Seattle-Score Features are extracted from another Dataset,   .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = [\n",
    "   \n",
    "    \n",
    "]\n",
    "\n",
    "target_col = 'price_holiday'\n",
    "\n",
    "model_listing(LinearRegression,train_cols,target_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To solve overfitting, Regularization is applied......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate regularized cost given alpha, mse and the model coefficients\n",
    "def reg_cost(alpha, mse, coeffs, model = None):\n",
    "    if model == \"lasso\":\n",
    "        return mse + alpha * np.sum(np.abs(coeffs))\n",
    "    elif model == \"ridge\":\n",
    "        return mse + alpha * np.linalg.norm(coeffs)\n",
    "    else:\n",
    "        return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_levels = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "x_train = listings_train[train_cols].values\n",
    "x_test = listings_test[train_cols].values\n",
    "y_train = listings_train[target_col].values\n",
    "y_test = listings_test[target_col].values\n",
    "\n",
    "for alpha_level in alpha_levels:\n",
    "    print(\"\\n At alpha Level: %0.2f \"% alpha_level)\n",
    "\n",
    "    lasso_lm = Lasso(alpha= alpha_level)\n",
    "\n",
    "    # Fit the model on to the training data( Train the model ).\n",
    "    lasso_lm.fit(x_train, y_train)\n",
    "\n",
    "    # Use the model to predict values\n",
    "    #y_pred = np.expm1(lm.predict(x_test))\n",
    "    y_pred = lasso_lm.predict(x_test)\n",
    "\n",
    "    # Calculate the Mean Squared Error using the mean_squared_error function.\n",
    "    print(\"Test Data\")\n",
    "    print(\"R^2 value using score fn: %.3f\" % lasso_lm.score(x_test,y_test))\n",
    "    print(\"Mean Squared Error : %0.3f\" % mean_squared_error(y_test,y_pred))\n",
    "    print(\"Root Mean Squared Error : %0.3f\" % (mean_squared_error(y_test,y_pred))**0.5)\n",
    "       \n",
    "    # Get model complexity using the user defined fn\n",
    "    print(\"Model Complexity: %0.3f\" % reg_cost(mse = 0, alpha = 1, coeffs= lasso_lm.coef_, model= \"lasso\"))\n",
    "    \n",
    "    # Get Regularized Cost using the user defined fn\n",
    "    print(\"Regularized Cost: %0.3f\" % reg_cost(mse = mean_squared_error(y_test,y_pred), alpha = alpha_level, coeffs= lasso_lm.coef_, model= \"lasso\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regresson Finished......"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4: Random Forest Regressor\n",
    "## Fit in all Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = [   \n",
    "]\n",
    "\n",
    "target_col = 'price_holiday'\n",
    "\n",
    "x_train = listings_train[train_cols].values\n",
    "x_test = listings_test[train_cols].values\n",
    "y_train = listings_train[target_col].values\n",
    "y_test = listings_test[target_col].values\n",
    "\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "#Create a random forest regressor\n",
    "clf = RandomForestRegressor(max_depth=10, n_estimators=100)\n",
    "\n",
    "#Train the regressor\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "#Plot variable importances for the top 10 predictors\n",
    "importances = clf.feature_importances_\n",
    "feat_names = train_cols\n",
    "tree_result = pd.DataFrame({'feature': feat_names, 'importance': importances})\n",
    "tree_result.sort_values(by='importance',ascending=False)[:10].plot(x='feature', y='importance', kind='bar',color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model to predict values\n",
    "y_pred = clf.predict(x_train)\n",
    "\n",
    "# Calculate the Mean Squared Error using the mean_squared_error function.\n",
    "print(\"Training Data\")\n",
    "print(\"R^2 value using score fn: %.3f\" % clf.score(x_train,y_train))\n",
    "print(\"Mean Squared Error : %0.3f\" % mean_squared_error(y_train,y_pred))\n",
    "print(\"Root Mean Squared Error : %0.3f\" % (mean_squared_error(y_train,y_pred))**0.5)\n",
    "\n",
    "\n",
    "print(\" ------------------------------------------ \")\n",
    "\n",
    "# Use the model to predict values\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "# Calculate the Mean Squared Error using the mean_squared_error function.\n",
    "print(\"Test Data\")\n",
    "print(\"R^2 value using score fn: %.3f\" % clf.score(x_test,y_test))\n",
    "print(\"Mean Squared Error : %0.3f\" % mean_squared_error(y_test,y_pred))\n",
    "print(\"Root Mean Squared Error : %0.3f\" % (mean_squared_error(y_test,y_pred))**0.5)\n",
    "\n",
    "print(\" ----------------------------------- \")\n",
    "\n",
    "# Plot of model's residuals:\n",
    "fig = plt.figure(figsize=(10,3))\n",
    "\n",
    "sns.regplot((y_test),(y_pred))\n",
    "plt.title(\"Residuals for the model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 5: Catboost Regressor \n",
    "## Fill in all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_data = []\n",
    "categorical_data = []\n",
    "for column in holiday_listings.columns:\n",
    "    if holiday_listings[column].dtype == \"object\":\n",
    "        categorical_data.append(column)\n",
    "    else:\n",
    "        numerical_data.append(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare categorical features indices, catboost needs the indices of caterical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_index(df, query_cols):\n",
    "    cols = listings_2.columns.values\n",
    "    sidx = np.argsort(cols)\n",
    "    return sidx[np.searchsorted(cols, query_cols, sorter=sidx)]\n",
    "\n",
    "categorical_feature_indices = column_index(X, categorical_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_feature_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = [\n",
    "\n",
    "\n",
    "]\n",
    "\n",
    "target_col = 'price_holiday'\n",
    "x_train = listings_train[train_cols].values\n",
    "x_test = listings_test[train_cols].values\n",
    "y_train = listings_train[target_col].values\n",
    "y_test = listings_test[target_col].values\n",
    "    \n",
    "print(\"Shape of Train and Test data\")\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "print(\" ------------------------------------------ \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refinement\n",
    "model =  CatBoostRegressor(iterations=700,\n",
    "                             learning_rate=0.01,\n",
    "                             depth=4,\n",
    "                             eval_metric='RMSE',\n",
    "                             random_seed = 42,\n",
    "                             bagging_temperature = 0.2,\n",
    "                             od_type='Iter',\n",
    "                             metric_period = 75,\n",
    "                             od_wait=100)\n",
    "model.fit(x_train, y_train,\n",
    "                 eval_set=(x_test, y_test),\n",
    "                 cat_features=categorical_feature_indices,\n",
    "                 use_best_model=True,plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Mean Squared Error using the mean_squared_error function.\n",
    "print(\"Training Data\")\n",
    "print(\"R^2 value using score fn: %.3f\" % model.score(x_train,y_train))\n",
    "print(\"Root Mean Squared Error : %0.3f\" % model.get_best_score()['learn']['RMSE'])\n",
    "\n",
    "\n",
    "print(\" ------------------------------------------ \")\n",
    "\n",
    "# Calculate the Mean Squared Error using the mean_squared_error function.\n",
    "print(\"Test Data\")\n",
    "print(\"R^2 value using score fn: %.3f\" % model.score(x_test,y_test))\n",
    "print(\"Root Mean Squared Error : %0.3f\" % (model.get_best_score()['validation']['RMSE'])\n",
    "\n",
    "print(\" ----------------------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_imp = pd.DataFrame({'imp': model.feature_importances_, 'col': holiday_listings.columns})\n",
    "fea_imp = fea_imp.sort_values(['imp', 'col'], ascending=[True, False]).iloc[-30:]\n",
    "fea_imp.plot(kind='barh', x='col', y='imp', figsize=(10, 15), legend=None)\n",
    "plt.title('CatBoost - Feature Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.xlabel('Importance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Comparison: Select the best model by comparing R^2 and RMSE\n",
    "*\n",
    "*\n",
    "*\n",
    "*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Results: Use Best Model to predict\n",
    "*\n",
    "*\n",
    "*\n",
    "*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}